{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Insert Creative Title HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries\n",
    "\n",
    "Intro to Pandas:\n",
    "https://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html\n",
    "\n",
    "Learning the Spotify API through spotipy:\n",
    "https://spotipy.readthedocs.io/en/latest/#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster, decomposition, metrics\n",
    "import plotly.graph_objects as go\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Tidying\n",
    "//TODO Talk about general authentication flow.<br>\n",
    "//TODO Link example resource. <br>\n",
    "//TODO Explain how to get the spotify username<br>\n",
    "//TODO talk about how we chose what columns to keep. Talk about how data is relatively simple and no need to reorganize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate authorization token for reading user library\n",
    "username = '12124976904'\n",
    "\n",
    "scope = 'user-library-read playlist-modify-public'\n",
    "client_id = '076ff5215a374d2481d0117877d79b74'\n",
    "client_secret = '0ff2fd29106e4b7ebd7da4152d4a20c3'\n",
    "redirect_uri = 'https://www.google.com/'\n",
    "\n",
    "token = util.prompt_for_user_token(username, scope, client_id, client_secret, redirect_uri)\n",
    "\n",
    "if token:\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "\n",
    "else:\n",
    "    print(\"Can't get token for\", username)\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO explain the code flow <br>\n",
    "//TODO talk about how we chose what columns to keep. <br>\n",
    "//TODO Talk about how data is relatively simple and no need to reorganize <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saved_tracks():\n",
    "    results = sp.current_user_saved_tracks()\n",
    "    tracks = results['items']\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "    return tracks\n",
    "\n",
    "print('Loading Saved Tracks Now. Please be patient!')\n",
    "\n",
    "if True:\n",
    "    tracks = get_saved_tracks()\n",
    "    features = []\n",
    "    track_info = []\n",
    "    artist_uris = {}\n",
    "    \n",
    "    for track in tracks:\n",
    "        track = track['track']\n",
    "        features.extend(sp.audio_features(track['uri']))\n",
    "        track_info.append([track['name'], track['artists'][0]['name']])\n",
    "        artist_uris[track['artists'][0]['name']] = track['artists'][0]['uri']\n",
    "\n",
    "    features = pd.DataFrame(features)\n",
    "    track_info = pd.DataFrame(track_info).rename(columns={0: \"title\", 1: \"artist\"})\n",
    "\n",
    "    features = features[['acousticness', 'danceability', 'energy', 'instrumentalness', 'tempo', 'valence']]\n",
    "    features['tempo'] = (features['tempo']-features['tempo'].min())/(features['tempo'].max()-features['tempo'].min())\n",
    "\n",
    "else:\n",
    "    features = pd.read_csv('sample_data') #TODO download the dataframe as a csv and add to path\n",
    "    \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explain the columns and how values are determined.\n",
    "# Summary Statistics\n",
    "# Histograms\n",
    "# Correlation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, sharex=True, figsize=(15,8))\n",
    "ax = ax.flatten()\n",
    "idx = 0\n",
    "\n",
    "for col in features.columns:\n",
    "    ax[idx].hist(features[col])\n",
    "    ax[idx].set_title(col + \" (mean: \" + str(np.round(features[col].mean(), 3)) + \")\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering & Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity = cluster.AffinityPropagation(preference=0).fit(features.values)\n",
    "pref = 0\n",
    "db_scores = {}\n",
    "\n",
    "while (len(affinity.cluster_centers_) > 6):\n",
    "    pref -= 1\n",
    "    affinity = cluster.AffinityPropagation(preference=pref).fit(features.values)\n",
    "    \n",
    "    if len(affinity.cluster_centers_) <= 10 and len(affinity.cluster_centers_) >= 6:\n",
    "        db_scores[metrics.davies_bouldin_score(features.values, affinity.labels_)] = affinity\n",
    "    \n",
    "db_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = db_scores[min(db_scores.keys())]\n",
    "features['Cluster'] = clusters.labels_\n",
    "track_info['Cluster'] = clusters.labels_\n",
    "track_info.iloc[clusters.cluster_centers_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can play with this to see the songs in each cluster\n",
    "track_info.loc[track_info['Cluster'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=2)\n",
    "features_2d = pd.DataFrame(pca.fit_transform(features.loc[:,:'valence']), columns=['Component 1', 'Component 2'])\n",
    "features_2d['Cluster'] = clusters.labels_\n",
    "print(pca.explained_variance_ratio_)\n",
    "features_2d.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'orange', 'yellow', 'pink', 'green', 'blue', 'purple', 'black', 'cyan', 'grey']\n",
    "fig, ax = plt.subplots(figsize=(16,11))\n",
    "features_2d = features_2d.sort_values('Cluster')\n",
    "\n",
    "for cluster_label in features_2d['Cluster'].unique():\n",
    "    group = features_2d.loc[features_2d['Cluster'] == cluster_label]\n",
    "    ax.scatter(group['Component 1'], group['Component 2'], c = colors[cluster_label], label=cluster_label, s=12)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, sharex=True, figsize=(16, 15))\n",
    "ax = ax.flatten()\n",
    "idx = 0\n",
    "\n",
    "for col in features.loc[:,:'valence'].columns:\n",
    "    seaborn.violinplot(features['Cluster'], features[col], ax=ax[idx])\n",
    "    ax[idx].set_title(col)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(int((len(clusters.cluster_centers_))/2) + 1, 2, sharex=True, figsize=(16, 15))\n",
    "ax = ax.flatten()\n",
    "idx = 0\n",
    "\n",
    "for cluster_label in features['Cluster'].unique():\n",
    "    group = features.loc[features['Cluster'] == cluster_label].drop('Cluster', axis=1)\n",
    "    group = group.melt()\n",
    "    seaborn.violinplot(x=group['variable'], y=group['value'], data=group, ax=ax[idx])\n",
    "    ax[idx].set_title(\"Cluster \" + str(cluster_label))\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Similar Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//general description of this section\n",
    "//describe the code blow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = track_info.groupby('artist').count().drop('Cluster', axis=1)\n",
    "artists = artists.reset_index().rename(columns={\"title\": \"count\"})\n",
    "artists = artists.sort_values('count', ascending=False).head(25)\n",
    "artists['uri'] = [artist_uris[artist] for artist in artists['artist']]\n",
    "artists.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//describe code below\n",
    "//explain parameters to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_tracks = []\n",
    "known_artists = set(track_info['artist'])\n",
    "\n",
    "for tup in artists.itertuples():\n",
    "    for artist in sp.artist_related_artists(tup.uri)['artists'][:12]:\n",
    "        \n",
    "        if artist['name'] not in known_artists:\n",
    "            known_artists.add(artist['name'])\n",
    "            \n",
    "            for track in sp.artist_top_tracks(artist['uri'])['tracks'][:5]:\n",
    "                related_tracks.append([track['name'], track['artists'][0]['name'], track['uri']])\n",
    "    \n",
    "related_tracks = pd.DataFrame(related_tracks).rename(columns={0: \"title\", 1: \"artist\", 2: \"uri\"})\n",
    "related_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//explain code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_features = []\n",
    "\n",
    "for uri in related_tracks['uri']:\n",
    "    rec_features.extend(sp.audio_features(uri))\n",
    "\n",
    "rec_features = pd.DataFrame(rec_features)\n",
    "rec_features = rec_features[['acousticness', 'danceability', 'energy', 'instrumentalness', 'tempo', 'valence']]\n",
    "rec_features['tempo'] = (rec_features['tempo']-rec_features['tempo'].min())/ \\\n",
    "                        (rec_features['tempo'].max()-rec_features['tempo'].min())\n",
    "rec_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//explain code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_features['cluster'] = clusters.predict(rec_features)\n",
    "rec_features['silhouette'] = metrics.silhouette_samples(rec_features.loc[:'valence'], rec_features['cluster'])\n",
    "rec_features[['title', 'artist', 'uri']] = related_tracks[['title', 'artist', 'uri']]\n",
    "rec_features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//explain code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = rec_features.groupby('cluster').apply(lambda x: x.sort_values('silhouette', ascending=False).head(12))\n",
    "grouped = grouped.reset_index(drop=True)\n",
    "\n",
    "grouped.groupby('cluster').mean()['silhouette']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//can pretty much say whats in the comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can play with this to see the songs in each playlist\n",
    "grouped.loc[grouped['cluster'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//explain code below\n",
    "//analyze graph output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2d = pd.DataFrame(pca.fit_transform(grouped.loc[:,:'valence']), columns=['Component 1', 'Component 2'])\n",
    "features_2d['cluster'] = grouped['cluster']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,11))\n",
    "features_2d = features_2d.sort_values('cluster')\n",
    "\n",
    "for cluster_label in features_2d['cluster'].unique():\n",
    "    group = features_2d.loc[features_2d['cluster'] == cluster_label]\n",
    "    ax.scatter(group['Component 1'], group['Component 2'], c = colors[cluster_label], label=cluster_label, s=12)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//explain code below\n",
    "//analyze graph output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(int((len(clusters.cluster_centers_ + 1))/2), 2, sharex=True, figsize=(16, 20))\n",
    "ax = ax.flatten()\n",
    "idx = 0\n",
    "\n",
    "for cluster_label in grouped['cluster'].unique():\n",
    "    saved = features.loc[features['Cluster'] == cluster_label].loc[:,:'valence'].mean()\n",
    "    recs = grouped.loc[grouped['cluster'] == cluster_label].loc[:,:'valence'].mean()\n",
    "\n",
    "    combined = pd.DataFrame(saved).rename(columns={0: \"saved\"})\n",
    "    combined['recs'] = recs\n",
    "    combined = combined.reset_index().melt(id_vars=['index'])\n",
    "    seaborn.barplot(x=combined['index'], y=combined['value'], hue=combined['variable'], data=group, ax=ax[idx])\n",
    "    \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//explain code below\n",
    "//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_label in grouped['cluster'].unique():\n",
    "    cluster_rec = grouped.loc[grouped['cluster'] == cluster_label]\n",
    "    feature_avgs = cluster.mean().drop(['cluster', 'silhouette'])\n",
    "    \n",
    "    name = \"\"\n",
    "    for feature in feature_avgs.keys():\n",
    "        if feature_avgs[feature] < 0.2:\n",
    "            name += \"Low \" + feature + \", \"\n",
    "        elif feature_avgs[feature] > 0.65:\n",
    "            name += \"High \" + feature + \", \"\n",
    "    name = name[:-2]\n",
    "    \n",
    "    playlist = sp.user_playlist_create(username, name)\n",
    "    sp.user_playlist_add_tracks(username, playlist['id'], cluster_rec['uri'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
